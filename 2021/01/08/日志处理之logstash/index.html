<!DOCTYPE html>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">

    

    

    <title>日志处理之logstash | 点滴诗词</title>
    <meta name="author" content="shiguofu">
    <meta name="version" content="1.0.0">
    <meta name="keywords" content>
    <meta name="description" content="IntroductionLogstash是一个开源数据收集引擎，具有实时管道功能。Logstash将来自不同数据源的数据统一搜集起来，并根据需求将数据标准化输出到你所选择的目的地。如下图所示。Input/Filter/OutputLogstash可以从多个数据源获取数据，并对其进行处理、转换，最后将其发送到不同类型的“存储”输入采集各种样式、大小和来源的数据分布式系统中，数据往往是以各种各样的形式(结构化、非结构话)存在于不同的节点中。Logstash 支持不同数据源的选择 ，日志...">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">

    
    <link rel="alternate" href="/atom.xml" title="点滴诗词" type="application/atom+xml">
    
    
    <link rel="icon" href="http://shiguofu.cn/favicon.ico">
    

    <link rel="stylesheet" href="/css/style.css">
</head>
<body>

    <main class="app">
        <header class="header clearfix">
    <div id="nav" class="nav">
    <div class="nav-mobile">
        <button id="open-panel" class="open-panel nav-mobile-item"><i class="icon-documents"></i></button>
        <h1 class="nav-mobile-title nav-mobile-item">点滴诗词</h1>
        <button id="open-menus" class="open-panel nav-mobile-item"><i class="icon-library"></i></button>
    </div>

    <nav id="nav-inner" class="nav-inner">
        
            <a class="nav-item" href="/">
                <span class="nav-text">首页</span>
            </a>
        
            <a class="nav-item" href="/categories/backend">
                <span class="nav-text">后端</span>
            </a>
        
            <a class="nav-item" href="/tags">
                <span class="nav-text">标签</span>
            </a>
        
            <a class="nav-item" href="/archives">
                <span class="nav-text">归档</span>
            </a>
        
            <a class="nav-item" href="/about">
                <span class="nav-text">关于</span>
            </a>
        
    </nav>
</div>

    <aside id="aside" class="aside">
    <div id="aside-mask" class="aside-mask"></div>
    <div id="aside-inner" class="aside-inner">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"><i class="icon-search-stroke"></i></button><input type="hidden" name="sitesearch" value="http://shiguofu2012.github.io"></form>

        
        
        
        

        
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Input-Filter-Output"><span class="toc-number">2.</span> <span class="toc-text">Input/Filter/Output</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#输入"><span class="toc-number">2.1.</span> <span class="toc-text">输入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#过滤器"><span class="toc-number">2.2.</span> <span class="toc-text">过滤器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#输出"><span class="toc-number">2.3.</span> <span class="toc-text">输出</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Install-amp-amp-config"><span class="toc-number">3.</span> <span class="toc-text">Install &amp;&amp; config</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#正则匹配"><span class="toc-number">3.0.1.</span> <span class="toc-text">正则匹配</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ip解析"><span class="toc-number">3.0.2.</span> <span class="toc-text">ip解析</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#字段增删改"><span class="toc-number">3.0.3.</span> <span class="toc-text">字段增删改</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#条件判断"><span class="toc-number">3.0.4.</span> <span class="toc-text">条件判断</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#json"><span class="toc-number">3.0.5.</span> <span class="toc-text">json</span></a></li></ol></li></ol><li class="toc-item toc-level-3"><a class="toc-link" href="#Example"><span class="toc-number">4.</span> <span class="toc-text">Example</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#总结"><span class="toc-number">5.</span> <span class="toc-text">总结</span></a></li>
        
    </div>
</aside>

</header>

        <div id="content" class="content"><article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            日志处理之logstash
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="http://shiguofu2012.github.io/2021/01/08/日志处理之logstash/index.html">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2021-01-08T05:19:59.000Z" itemprop="datePublished">2021-01-08</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/service/">service</a>, <a class="article-tag-link" href="/tags/日志处理/">日志处理</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Logstash是一个开源数据收集引擎，具有实时管道功能。Logstash将来自不同数据源的数据统一搜集起来，并根据需求将数据标准化输出到你所选择的目的地。如下图所示。</p>
<p><img src="/2021/01/08/日志处理之logstash/874963-20180811151005760-1802603955.png" alt="img"></p>
<h3 id="Input-Filter-Output"><a href="#Input-Filter-Output" class="headerlink" title="Input/Filter/Output"></a>Input/Filter/Output</h3><p>Logstash可以从多个数据源获取数据，并对其进行处理、转换，最后将其发送到不同类型的“存储”</p>
<h4 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h4><p>采集各种样式、大小和来源的数据</p>
<p>分布式系统中，数据往往是以各种各样的形式(结构化、非结构话)存在于不同的节点中。Logstash 支持不同数据源的选择 ，日志、报表、数据库的内容等等。可以在同一时间从众多常用来源捕捉事件。</p>
<ul>
<li>文件类型</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">input&#123;</span><br><span class="line">    file&#123;</span><br><span class="line">        # path属性接受的参数是一个数组，其含义是标明需要读取的文件位置</span><br><span class="line">        path =&gt; [‘pathA’，‘pathB’]</span><br><span class="line">        </span><br><span class="line">        # 表示多就去path路径下查看是够有新的文件产生。默认是15秒检查一次。</span><br><span class="line">        discover_interval =&gt; 15</span><br><span class="line">        </span><br><span class="line">        # 排除那些文件，也就是不去读取那些文件</span><br><span class="line">        exclude =&gt; [‘fileName1’,‘fileNmae2’]</span><br><span class="line">        </span><br><span class="line">        # 被监听的文件多久没更新后断开连接不在监听，默认是一个小时。</span><br><span class="line">        close_older =&gt; 3600</span><br><span class="line">        </span><br><span class="line">        # 在每次检查文件列 表的时候， 如果一个文件的最后 修改时间 超过这个值， 就忽略这个文件。 默认一天。</span><br><span class="line">        ignore_older =&gt; 86400</span><br><span class="line">        </span><br><span class="line">        # logstash 每隔多久检查一次被监听文件状态（是否有更新）， 默认是 1 秒。</span><br><span class="line">        stat_interval =&gt; 1</span><br><span class="line">        </span><br><span class="line">        #sincedb记录数据上一次的读取位置的一个index</span><br><span class="line">        sincedb_path =&gt; ’$HOME/. sincedb‘</span><br><span class="line">        </span><br><span class="line">        #logstash 从什么 位置开始读取文件数据， 默认是结束位置 也可以设置为：beginning 从头开始</span><br><span class="line">        start_position =&gt; ‘beginning’</span><br><span class="line">        </span><br><span class="line">        # 注意：这里需要提醒大家的是，如果你需要每次都从开始读取文件的话，只设置start_position =&gt; beginning是没有用的，你可以选择sincedb_path 定义为 /dev/null</span><br><span class="line">    &#125;           </span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>数据库类型</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">input&#123;</span><br><span class="line">    jdbc&#123;</span><br><span class="line">    # jdbc sql server 驱动,各个数据库都有对应的驱动，需自己下载</span><br><span class="line">    jdbc_driver_library =&gt; &quot;/etc/logstash/driver.d/sqljdbc_2.0/enu/sqljdbc4.jar&quot;</span><br><span class="line">    #jdbc class 不同数据库有不同的 class 配置</span><br><span class="line">    jdbc_driver_class =&gt; &quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;</span><br><span class="line">    #配置数据库连接 ip 和端口，以及数据库   </span><br><span class="line">    jdbc_connection_string =&gt; &quot;jdbc:sqlserver://xxxxxx:1433;databaseName=test_db&quot;</span><br><span class="line">    #配置数据库用户名</span><br><span class="line">    jdbc_user =&gt;   </span><br><span class="line">    #配置数据库密码</span><br><span class="line">    jdbc_password =&gt;</span><br><span class="line">    </span><br><span class="line">    # 上面这些主要配置数据库java驱动，账号配置</span><br><span class="line">    # 定时器 多久执行一次SQL，默认是一分钟</span><br><span class="line">    # schedule =&gt; 分 时 天 月 年  </span><br><span class="line">    # schedule =&gt; * 22  *  *  * 表示每天22点执行一次</span><br><span class="line">    schedule =&gt; &quot;* * * * *&quot;</span><br><span class="line">    # 是否清除 last_run_metadata_path 的记录,如果为真那么每次都相当于从头开始查询所有的数据库记录</span><br><span class="line">    clean_run =&gt; false</span><br><span class="line">    # 是否需要记录某个column 的值,如果 record_last_run 为真,可以自定义我们需要表的字段名称，</span><br><span class="line">    #此时该参数就要为 true. 否则默认 track 的是 timestamp 的值.</span><br><span class="line">    use_column_value =&gt; true</span><br><span class="line">    #如果 use_column_value 为真,需配置此参数. 这个参数就是数据库给出的一个字段名称。当然该字段必须是递增的，可以是 数据库的数据时间这类的</span><br><span class="line">    tracking_column =&gt; create_time</span><br><span class="line">    #是否记录上次执行结果, 如果为真,将会把上次执行到的 tracking_column 字段的值记录下来,保存到 last_run_metadata_path 指定的文件中</span><br><span class="line">    record_last_run =&gt; true</span><br><span class="line">    # 我们只需要在 SQL 语句中 WHERE MY_ID &gt; :last_sql_value 即可. 其中 :last_sql_value 取得就是该文件中的值</span><br><span class="line">    last_run_metadata_path =&gt; &quot;/etc/logstash/run_metadata.d/my_info&quot;</span><br><span class="line">    # 是否将字段名称转小写。</span><br><span class="line">    # 这里有个小的提示，如果你之前就处理过一次数据，并且在Kibana中有对应的搜索需求的话，还是改为true，</span><br><span class="line">    # 因为默认是true，并且Kibana是大小写区分的。准确的说应该是ES大小写区分</span><br><span class="line">    lowercase_column_names =&gt; false</span><br><span class="line">    # 你的SQL的位置，当然，你的SQL也可以直接写在这里。</span><br><span class="line">    # statement =&gt; SELECT * FROM tabeName t WHERE  t.creat_time &gt; :last_sql_value</span><br><span class="line">    statement_filepath =&gt; &quot;/etc/logstash/statement_file.d/my_info.sql&quot;</span><br><span class="line">    # 数据类型，标明数据来源，es索引的时候可以建立不同的额索引</span><br><span class="line">    type =&gt; &quot;my_info&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    # 注意：外在的SQL文件就是一个文本文件就可以了，还有需要注意的是，一个jdbc&#123;&#125;插件就只能处理一个SQL语句，</span><br><span class="line">    # 如果你有多个SQL需要处理的话，只能在重新建立一个jdbc&#123;&#125;插件。</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>beats</li>
</ul>
<p>主要是接受filebeats的数据导入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  beats &#123;</span><br><span class="line">    # 接受数据端口</span><br><span class="line">    port =&gt; 5044</span><br><span class="line">    # 数据类型</span><br><span class="line">    type =&gt; &quot;logs&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h4><p><strong>实时解析和转换数据</strong></p>
<p>数据从源传输到存储库的过程中，需要对不同的数据进行不同的存储，Logstash 过滤器能够解析每条记录，识别每条数据的字段内容，并将它们转换成自定义数据，以便进行处理分析计算。</p>
<p>Logstash 动态地转换和解析数据，支持各种格式或复杂度数据的解析：</p>
<ul>
<li>利用 Grok 从非结构化数据中派生出结构</li>
<li>从 IP 地址破译出地理坐标</li>
<li>将 PII 数据匿名化，完全排除敏感字段</li>
<li>整体处理不受数据源、格式或架构的影响</li>
</ul>
<h4 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h4><p>尽管 ES是logstash的常用输出方向，能够为我们的搜索和分析带来无限可能，但它并非唯一选择。</p>
<p>Logstash 提供众多输出选择，您可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。</p>
<p><img src="/2021/01/08/日志处理之logstash/874963-20180811150315582-1149748851.png" alt="img"></p>
<h3 id="Install-amp-amp-config"><a href="#Install-amp-amp-config" class="headerlink" title="Install &amp;&amp; config"></a>Install &amp;&amp; config</h3><ul>
<li>安装</li>
</ul>
<p>安装比较简单，官网直接有现成的二进制包，下载地址： <a href="https://artifacts.elastic.co/downloads/logstash/logstash-7.10.1-linux-x86_64.tar.gz" target="_blank" rel="noopener">https://artifacts.elastic.co/downloads/logstash/logstash-7.10.1-linux-x86_64.tar.gz</a></p>
<p>安装也比较简单，解压设置path即可使用。</p>
<p>本人经常使用，就写了个安装elk的脚本，需要的可以拿去使用：<a href="https://github.com/shiguofu2012/scripts/blob/master/install_elk.sh。" target="_blank" rel="noopener">https://github.com/shiguofu2012/scripts/blob/master/install_elk.sh。</a></p>
<ul>
<li>配置intput/output</li>
</ul>
<p>Logstash配置有两个必需的元素，输入和输出，以及一个可选过滤器。输入插件从数据源那里消费数据，过滤器插件根据你的期望修改数据，输出插件将数据写入目的地。</p>
<p><img src="/2021/01/08/日志处理之logstash/shiguofu/Documents/%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%E4%B9%8Blogstash/logstash-ifo.png" alt="img"></p>
<ol>
<li>接下来，允许Logstash最基本的管道，例如：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-145-82-centos ~]# logstash -e 'input &#123; stdin &#123;&#125; &#125; output &#123; stdout &#123;&#125; &#125;'</span><br><span class="line">Sending Logstash logs to /usr/local/logstash/logs which is now configured via log4j2.properties</span><br><span class="line">[2021-01-07T22:15:40,409][INFO ][logstash.runner          ] Starting Logstash &#123;"logstash.version"=&gt;"7.9.3", "jruby.version"=&gt;"jruby 9.2.13.0 (2.5.7) 2020-08-03 9a89c94bcc Java HotSpot(TM) 64-Bit Server VM 25.261-b12 on 1.8.0_261-b12 +indy +jit [linux-x86_64]"&#125;</span><br><span class="line">[2021-01-07T22:15:40,803][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified</span><br><span class="line">[2021-01-07T22:15:42,097][INFO ][org.reflections.Reflections] Reflections took 39 ms to scan 1 urls, producing 22 keys and 45 values</span><br><span class="line">[2021-01-07T22:15:43,158][INFO ][logstash.javapipeline    ][main] Starting pipeline &#123;:pipeline_id=&gt;"main", "pipeline.workers"=&gt;8, "pipeline.batch.size"=&gt;125, "pipeline.batch.delay"=&gt;50, "pipeline.max_inflight"=&gt;1000, "pipeline.sources"=&gt;["config string"], :thread=&gt;"#&lt;Thread:0x41654bea run&gt;"&#125;</span><br><span class="line">[2021-01-07T22:15:43,809][INFO ][logstash.javapipeline    ][main] Pipeline Java execution initialization time &#123;"seconds"=&gt;0.64&#125;</span><br><span class="line">[2021-01-07T22:15:43,866][INFO ][logstash.javapipeline    ][main] Pipeline started &#123;"pipeline.id"=&gt;"main"&#125;</span><br><span class="line">The stdin plugin is now waiting for input:</span><br><span class="line">[2021-01-07T22:15:43,914][INFO ][logstash.agent           ] Pipelines running &#123;:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]&#125;</span><br><span class="line">[2021-01-07T22:15:44,235][INFO ][logstash.agent           ] Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;</span><br><span class="line">&#123;</span><br><span class="line">          "host" =&gt; "VM-145-82-centos",</span><br><span class="line">       "message" =&gt; "",</span><br><span class="line">    "@timestamp" =&gt; 2021-01-07T14:15:43.902Z,</span><br><span class="line">      "@version" =&gt; "1"</span><br><span class="line">&#125;</span><br><span class="line">hello</span><br><span class="line">&#123;</span><br><span class="line">          "host" =&gt; "VM-145-82-centos",</span><br><span class="line">       "message" =&gt; "hello",</span><br><span class="line">    "@timestamp" =&gt; 2021-01-07T14:15:47.996Z,</span><br><span class="line">      "@version" =&gt; "1"</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">          "host" =&gt; "VM-145-82-centos",</span><br><span class="line">       "message" =&gt; "",</span><br><span class="line">    "@timestamp" =&gt; 2021-01-07T14:15:50.766Z,</span><br><span class="line">      "@version" =&gt; "1"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从标准输入获取数据，输出到标准输出。</p>
<ol start="2">
<li>input 从filebeat获取数据</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  beats &#123;</span><br><span class="line">    host =&gt; "0.0.0.0"   # 默认是127.0.0.1 只能本级访问</span><br><span class="line">    port =&gt; 5044</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#</span> output 索引至es</span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; ["localhost:9200"]       # es地址</span><br><span class="line">    user =&gt; "xxxx"       # 用户名</span><br><span class="line">    password =&gt; "xxxx"   # 密码</span><br><span class="line">    index =&gt; "test-ap-%&#123;+YYYY.MM.dd&#125;" # 建立的索引，这里默认每天建一个索引</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>总体来讲，input/output是比较容易配置的，关键是对数据进行格式化。</p>
<ul>
<li>filter</li>
</ul>
<h5 id="正则匹配"><a href="#正则匹配" class="headerlink" title="正则匹配"></a>正则匹配</h5><p>grok 匹配非格式化字段，提取字段格式化数据，强大的文本解析工具，支持正则表达式</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">grok &#123;</span><br><span class="line">    match =&gt; &#123; "[message]" =&gt; "%&#123;TIMESTAMP_ISO8601:_timestamp&#125; %&#123;LOGLEVEL:level&#125; %&#123;DATA:stack&#125;" &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    # 解析失败的处理</span><br><span class="line">    if "_grokparsefailure" in [tags] &#123;</span><br><span class="line">      mutate &#123;</span><br><span class="line">        rename =&gt; ["message", "msg"]</span><br><span class="line">        remove_field =&gt; ["tags"]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h5 id="ip解析"><a href="#ip解析" class="headerlink" title="ip解析"></a>ip解析</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">    geoip &#123;</span><br><span class="line">        source =&gt; "ip"</span><br><span class="line">        fields =&gt; ["city_name", "timezone"]   # 选择解析的字段</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>解析出来的数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    "ip" =&gt; "183.60.92.253",</span><br><span class="line">    "@version" =&gt; "1",</span><br><span class="line">    "@timestamp" =&gt; "2014-08-07T10:32:55.610Z",</span><br><span class="line">    "host" =&gt; "raochenlindeMacBook-Air.local",</span><br><span class="line">    "geoip" =&gt; &#123;</span><br><span class="line">        "ip" =&gt; "183.60.92.253",</span><br><span class="line">        "country_code2" =&gt; "CN",</span><br><span class="line">        "country_code3" =&gt; "CHN",</span><br><span class="line">        "country_name" =&gt; "China",</span><br><span class="line">        "continent_code" =&gt; "AS",</span><br><span class="line">        "region_name" =&gt; "30",</span><br><span class="line">        "city_name" =&gt; "Guangzhou",</span><br><span class="line">        "latitude" =&gt; 23.11670000000001,</span><br><span class="line">        "longitude" =&gt; 113.25,</span><br><span class="line">        "timezone" =&gt; "Asia/Chongqing",</span><br><span class="line">        "real_region_name" =&gt; "Guangdong",</span><br><span class="line">        "location" =&gt; [</span><br><span class="line">            [0] 113.25,</span><br><span class="line">            [1] 23.11670000000001</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="字段增删改"><a href="#字段增删改" class="headerlink" title="字段增删改"></a>字段增删改</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">  mutate &#123;</span><br><span class="line">    remove_field =&gt; ["ecs", "input", "agent", "tags", "@version", "@metadata"]   # 移除字段</span><br><span class="line">    rename =&gt; ["host", "my_host"]   # 重命名</span><br><span class="line">    rename =&gt; ["kubernetes", "my_k8s"]   # 重命名</span><br><span class="line">    remove_field =&gt; ["[host][mac]", "[my_host][containerized]", "[my_host][os]", "[my_host][id]", "[my_host][name]", "[my_host][architecture]"]   # 移除字段，使用已经重命名的字段</span><br><span class="line">    add_field =&gt; &#123; "mytype" =&gt; "type" &#125;   # 增加字段</span><br><span class="line">    </span><br><span class="line">    update =&gt; &#123; "sample" =&gt; "My new message" &#125;   # 更新字段内容，如果字段不存在，不会新建</span><br><span class="line">    replace =&gt; &#123; "message" =&gt; "%&#123;source_host&#125;: My new message" &#125; # 与 update 功能相同，区别在于如果字段不存在则会新建字段</span><br><span class="line">    convert =&gt; ["request_time", "float"]  # 数据类型转换</span><br><span class="line">    uppercase =&gt; [ "fieldname" ]    # 大写转换</span><br><span class="line">    lowercase =&gt; [ "fieldname" ]</span><br><span class="line">    </span><br><span class="line">    # 提供正则表达式替换</span><br><span class="line">    gsub =&gt; [</span><br><span class="line">        # replace all forward slashes with underscore</span><br><span class="line">        "fieldname", "/", "_",</span><br><span class="line">        # replace backslashes, question marks, hashes, and minuses</span><br><span class="line">        # with a dot "."</span><br><span class="line">        "fieldname2", "[\\?#-]", "."</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="条件判断"><a href="#条件判断" class="headerlink" title="条件判断"></a>条件判断</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line"><span class="meta">  #</span> 条件判断，字段my_k8s是否存在; 并且日志路径匹配</span><br><span class="line">  if ![my_k8s] and [log][file][path] =~ "/data/project_log/[\w-]+/[\w-\\.]+.log"  &#123;</span><br><span class="line">    mutate &#123;</span><br><span class="line">      split =&gt; ["[log][file][path]", "/"]   </span><br><span class="line">      # split操作 /data/project_log/app1/app.log =&gt; ["", data, project_log, app1, app.log]</span><br><span class="line">      add_field =&gt; &#123; "[kubernets][labels][app]" =&gt; "%&#123;[log][file][path][3]&#125;" &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"><span class="meta">  #</span> 字段操作放在mutate中</span><br><span class="line">  mutate &#123;</span><br><span class="line">    remove_field =&gt; [ "log" ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="json"><a href="#json" class="headerlink" title="json"></a>json</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line"><span class="meta">  #</span> 检查是否是json格式</span><br><span class="line">  if [message] =~ "^\&#123;.*\&#125;[\s\S]*$" &#123;</span><br><span class="line">    json &#123;</span><br><span class="line">      source =&gt; "[message]"</span><br><span class="line">      target =&gt; "jsoncontent"</span><br><span class="line">    &#125;</span><br><span class="line">    # json 数据失败</span><br><span class="line">    if "_jsonparsefailure" in [tags] &#123;</span><br><span class="line">      mutate &#123;</span><br><span class="line">        rename =&gt; ["message", "msg"]</span><br><span class="line">        remove_field =&gt; ["tags"]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>这里介绍一个曾经搭建的ELK日志系统。</p>
<p>结构比较简单，kubetnets中filebeat damonSet方式运行，搜集所有container 标准输出的日志，并传入logstash中，logstash将数据导入elasticsearch。结构图如下所示：</p>
<p><img src="/2021/01/08/日志处理之logstash/image-20210111133718737.png" alt="image-20210111133718737"></p>
<p>下面开始logstash的配置:</p>
<p>input比较简单，使用filebeat搜集日志，传入logstash</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  beats &#123;</span><br><span class="line">    host =&gt; "0.0.0.0"</span><br><span class="line">    port =&gt; 5044</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>output增加了几个条件判断，根据不同的字段日志类型，索引到不同的es索引中；如下所示</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line"><span class="meta">  #</span> k8s app 索引到对应的app中</span><br><span class="line">  if ([kubernetes][labels][app]) &#123;</span><br><span class="line">    if ([type] == "app") &#123;</span><br><span class="line">      elasticsearch &#123;</span><br><span class="line">        hosts =&gt; ["localhost:9200"]</span><br><span class="line">        index =&gt; "%&#123;[kubernetes][labels][app]&#125;-%&#123;+YYYY.MM.dd&#125;"</span><br><span class="line">      &#125;</span><br><span class="line">    # 根据type区分索引</span><br><span class="line">    &#125; else if ([type] == "user") &#123;</span><br><span class="line">        elasticsearch &#123;</span><br><span class="line">          hosts =&gt; ["localhost:9200"]</span><br><span class="line">          index =&gt; "%&#123;[kubernetes][labels][app]&#125;-[type]%&#123;+YYYY.MM.dd&#125;"</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      elasticsearch &#123;</span><br><span class="line">        hosts =&gt; ["localhost:9200"]</span><br><span class="line">        index =&gt; "%&#123;[kubernetes][labels][app]&#125;-%&#123;+YYYY.MM.dd&#125;"</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="meta">  #</span> 不存在k8s app字段</span><br><span class="line">  &#125; else if ([type] == "user") &#123;</span><br><span class="line">      elasticsearch &#123;</span><br><span class="line">        hosts =&gt; ["localhost:9200"]</span><br><span class="line">        index =&gt; "default-%&#123;+YYYY.MM.dd&#125;"</span><br><span class="line">      &#125;</span><br><span class="line">  &#125; else if ([type] == "app") &#123;</span><br><span class="line">      elasticsearch &#123;</span><br><span class="line">        hosts =&gt; ["localhost:9200"]</span><br><span class="line">        index =&gt; "default-%&#123;+YYYY.MM.dd&#125;"</span><br><span class="line">      &#125;</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">      elasticsearch &#123;</span><br><span class="line">        hosts =&gt; ["localhost:9200"]</span><br><span class="line">        index =&gt; "default-v1.0.0"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>filter 配置，不同的日志格式，输出格式化的数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">  mutate &#123;</span><br><span class="line">    # 移除filebeat发送的多余字段</span><br><span class="line">    remove_field =&gt; ["ecs", "input", "agent", "tags", "@version", "@metadata"]</span><br><span class="line">    remove_field =&gt; ["[host][mac]", "[host][containerized]", "[host][os]", "[host][id]", "[host][name]", "[host][architecture]"]</span><br><span class="line">  &#125;</span><br><span class="line">  if ![kubernetes] and [log][file][path] =~ "/data/app_log/[\w-]+/[\w\.-]+.log"  &#123;</span><br><span class="line">    mutate &#123;</span><br><span class="line">      split =&gt; ["[log][file][path]", "/"]</span><br><span class="line">      add_field =&gt; &#123; "[kubernetes][labels][app]" =&gt; "%&#123;[log][file][path][3]&#125;-host" &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  mutate &#123;</span><br><span class="line">    remove_field =&gt; [ "log" ]</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  if [message] =~ "^\&#123;.*\&#125;[\s\S]*$" &#123;</span><br><span class="line">    # json格式处理</span><br><span class="line">    json &#123;</span><br><span class="line">      source =&gt; "[message]"</span><br><span class="line">    &#125;</span><br><span class="line">    if "_jsonparsefailure" in [tags] &#123;</span><br><span class="line">        mutate &#123;</span><br><span class="line">            rename =&gt; ["message", "msg"]</span><br><span class="line">            remove_field =&gt; ["tags"]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if ([time]) &#123;</span><br><span class="line">      date &#123;</span><br><span class="line">        match =&gt; ["time", "ISO8601", "UNIX", "UNIX_MS", "TAI64N"]</span><br><span class="line">        target =&gt; "@timestamp"</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      mutate &#123;</span><br><span class="line">        remove_field =&gt; ["time"]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    # docker 日志格式 </span><br><span class="line">    if [log] =~ "^\&#123;.*\&#125;[\s\S]*$" &#123;</span><br><span class="line">      json &#123;</span><br><span class="line">        source =&gt; "[log]"</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      mutate &#123;</span><br><span class="line">        remove_field =&gt; ["log"]</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      if ([start_time]) &#123;</span><br><span class="line">        date &#123;</span><br><span class="line">          match =&gt; ["start_time", "ISO8601", "UNIX", "UNIX_MS", "TAI64N"]</span><br><span class="line">          target =&gt; "start_time"</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      if ([app_start_time]) &#123;</span><br><span class="line">        date &#123;</span><br><span class="line">          match =&gt; ["app_start_time", "ISO8601", "UNIX", "UNIX_MS", "TAI64N"]</span><br><span class="line">          target =&gt; "app_start_time"</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      if ([end_time]) &#123;</span><br><span class="line">        date &#123;</span><br><span class="line">          match =&gt; ["end_time", "ISO8601", "UNIX", "UNIX_MS", "TAI64N"]</span><br><span class="line">          target =&gt; "end_time"</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      if ([timestamp]) &#123;</span><br><span class="line">        date &#123;</span><br><span class="line">          match =&gt; ["timestamp", "ISO8601", "UNIX", "UNIX_MS", "TAI64N"]</span><br><span class="line">          target =&gt; "@timestamp"</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      if ([timestamp]) &#123;</span><br><span class="line">        date &#123;</span><br><span class="line">          match =&gt; ["timestamp", "ISO8601", "UNIX", "UNIX_MS", "TAI64N"]</span><br><span class="line">          target =&gt; "@timestamp"</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">    # 匹配日志格式</span><br><span class="line">    grok &#123;</span><br><span class="line">      match =&gt; &#123; "[message]" =&gt; "%&#123;TIMESTAMP_ISO8601:_timestamp&#125; %&#123;LOGLEVEL:level&#125; %&#123;DATA:stack&#125; - (?&lt;message&gt;(.|\r|\n|\t)*)" &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    # 匹配格式失败处理</span><br><span class="line">    if "_grokparsefailure" in [tags] &#123;</span><br><span class="line">      mutate &#123;</span><br><span class="line">        rename =&gt; ["message", "msg"]</span><br><span class="line">        remove_field =&gt; ["tags"]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    # 解析时间格式</span><br><span class="line">    date &#123;</span><br><span class="line">      match =&gt; ["_timestamp", "ISO8601", "UNIX", "UNIX_MS", "TAI64N"]</span><br><span class="line">      target =&gt; "@timestamp"</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    mutate &#123;</span><br><span class="line">      remove_field =&gt; ["_timestamp"]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  mutate &#123;</span><br><span class="line">    remove_field =&gt; ["message"]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>总之 ，logstash具备强大的功能，将不同数据源的数据经过清洗格式化，转化为结构化的数据，存储到不同的存储单元。</p>

        
    </section>
</article>



</div>
        <footer class="footer">
    Powered by <a href="http://shiguofu.cn" target="_blank">carlshi</a>,  <a href="https://beian.miit.gov.cn/" target="_blank">鄂ICP备18003559号-1</a>

    
</footer>

    </main>

    <script type="text/javascript" src="https://cdn.bootcss.com/jquery/1.9.0/jquery.min.js"></script>
    <script type="text/javascript">
    $(function() {
        var nodes = {
            nav: $('#nav'),
            aside: $('#aside'),
            asideInner: $('#aside-inner'),
            navInner: $('#nav-inner')
        };

        var doing = false;
        nodes.asideInner.on('webkitAnimationEnd mozAnimationEnd oAnimationEnd oanimationend animationend', function() {
            if (nodes.aside.hasClass('mobile-open')) {
                nodes.aside.removeClass('mobile-open');
            } else {
                nodes.aside.removeClass('mobile-close panel-show');
            }
            doing = false;
        });
        $('#open-panel, #aside-mask').on('click', function() {
            if (doing) {
                return;
            }
            
            if (nodes.aside.hasClass('panel-show')) {
                nodes.aside.addClass('mobile-close');
            } else {
                nodes.aside.addClass('mobile-open panel-show');
            }
        });
        $('#open-menus').on('click', function() {
            nodes.navInner.slideToggle();
        });

        if (window.innerWidth <= 960) {
            setTimeout(function() {
                nodes.navInner.slideUp();
            }, 3000);
        }
    });
    </script>
    
        <script type="text/javascript" src="/js/scrollspy.min.js"></script>
        <script type="text/javascript">
        $(document.body).scrollspy({target: '#aside-inner'});
        </script>
    

</body>
</html>
